{"paragraphs":[{"text":"%md\n\n# Spark Exasol Connector Usage Examples\n","user":"anonymous","dateUpdated":"2018-10-11T13:01:04+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539262860173_548912960","id":"20181011-130100_1074549517","dateCreated":"2018-10-11T13:01:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5720","dateFinished":"2018-10-11T13:01:05+0000","dateStarted":"2018-10-11T13:01:04+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Spark Exasol Connector Usage Examples</h1>\n"}]}},{"text":"%spark\n\n// Check that Spark Interpreter works\n\nval df = spark\n    .createDataFrame(Seq((1, \"andy\", 20, \"USA\"), (2, \"jeff\", 23, \"China\"), (3, \"james\", 18, \"USA\")))\n    .toDF(\"id\", \"name\", \"age\", \"country\")\n\ndf.printSchema\ndf.show()","user":"anonymous","dateUpdated":"2018-10-11T12:57:52+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539262664429_1684198050","id":"20181011-095309_222634679","dateCreated":"2018-10-11T12:57:44+0000","dateStarted":"2018-10-11T12:57:52+0000","dateFinished":"2018-10-11T12:58:23+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5323"},{"text":"%spark\n\nval queryStr = \"\"\"                                                                                 \n    WITH base AS (                                                                                \n        SELECT VALUE2PROC(POSITION_ID) AS HOME_NODE                                          \n        FROM   TEST.SALES_POSITIONS                                                       \n    )                                                                                \n    SELECT HOME_NODE, COUNT(*) AS CNT                                                \n    FROM base                                                                        \n    GROUP BY HOME_NODE                                                               \n\"\"\"                                                                                  \n\nval exaDF = spark.read\n    .format(\"exasol\")\n    .option(\"host\", \"10.0.0.11\")                                                                 \n    .option(\"port\", \"8563\")                                                                 \n    .option(\"username\", \"sys\")                                                     \n    .option(\"password\", \"exasol1\")                                                               \n    .option(\"query\", queryStr)                                                                   \n    .load()\n\nexaDF.collect().foreach(println)","user":"anonymous","dateUpdated":"2018-10-11T12:58:28+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539262664430_1685352297","id":"20181011-091923_18751249","dateCreated":"2018-10-11T12:57:44+0000","dateStarted":"2018-10-11T12:58:28+0000","dateFinished":"2018-10-11T12:58:31+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5324"},{"text":"%pyspark\n\nqueryStr = ' '.join((                                                                                \n    \"WITH base AS (\",                                                                              \n    \"SELECT VALUE2PROC(POSITION_ID) AS NODE_ID\",                                                   \n    \"FROM TEST.SALES_POSITIONS\",                                                                   \n    \")\",                                                                                           \n    \"SELECT NODE_ID, COUNT(*) AS CNT FROM base GROUP BY NODE_ID\"                                   \n  ))\n\nexaDF = spark.read \\\n    .format(\"exasol\") \\\n    .option(\"host\", \"10.0.0.11\") \\\n    .option(\"port\", \"8563\") \\\n    .option(\"username\", \"sys\") \\\n    .option(\"password\", \"exasol1\") \\\n    .option(\"query\", queryStr) \\\n    .load()\n    \nexaDF.collect()\n\nprint exaDF.count()","dateUpdated":"2018-10-11T12:57:44+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539262664430_1685352297","id":"20181011-091924_1008369693","dateCreated":"2018-10-11T12:57:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5325"},{"text":"%spark\n\nval queryStr = \"\"\"\n    SELECT s.SALES_DATE, s.MARKET_ID, sp.ARTICLE_ID, sp.AMOUNT\n    FROM TEST.SALES s \n    JOIN TEST.SALES_POSITIONS sp \n    ON s.SALES_ID = sp.SALES_ID\n    WHERE s.MARKET_ID IN (661, 534, 678, 1990)\n\"\"\"\n\nval exaDF = spark.read\n    .format(\"exasol\")\n    .option(\"host\", \"10.0.0.11\")                                                                 \n    .option(\"port\", \"8563\")                                                                 \n    .option(\"username\", \"sys\")                                                     \n    .option(\"password\", \"exasol1\")                                                               \n    .option(\"query\", queryStr)                                                                   \n    .load()\n\n// exaDF.collect().foreach(println) // GC due to collect to driver\n\nval groupedDF = exaDF\n    .groupBy(\"SALES_DATE\")\n    .agg(\n        sum(\"AMOUNT\"),\n        count(\"ARTICLE_ID\").alias(\"ARTICLE_CNT\")\n    )\n    .sort($\"SALES_DATE\".desc)\n\n// groupedDF.collect().foreach(println)\n\nprintln(groupedDF.count())","dateUpdated":"2018-10-11T12:57:44+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539262664431_1684967548","id":"20181011-101539_1141011317","dateCreated":"2018-10-11T12:57:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5326"},{"text":"%spark\n\nval queryStr = \"\"\"\n    SELECT s.SALES_DATE, s.MARKET_ID, s.TERMINAL_ID, s.PRICE, sp.AMOUNT, sp.ARTICLE_ID, sp.SALES_ID\n    FROM TEST.SALES s \n    JOIN TEST.SALES_POSITIONS sp \n    ON s.SALES_ID = sp.SALES_ID\n\"\"\"\n\nval exaDF = spark.read\n    .format(\"exasol\")\n    .option(\"host\", \"10.0.0.11\")                                                                 \n    .option(\"port\", \"8563\")                                                                 \n    .option(\"username\", \"sys\")                                                     \n    .option(\"password\", \"exasol1\")                                                               \n    .option(\"query\", queryStr)                                                                   \n    .load()\n\nval transformedDF = exaDF\n    .filter($\"MARKET_ID\".isin(661, 534, 678, 1990))\n\nval groupedDF = transformedDF\n    .groupBy(\"SALES_DATE\")\n    .agg(\n        sum(\"AMOUNT\"),\n        countDistinct(\"ARTICLE_ID\").alias(\"ARTICLE_CNT\")\n    )\n    .sort($\"SALES_DATE\".desc)\n\n// groupedDF.collect().foreach(println)\n\nprintln(groupedDF.count())\n\nprintln(groupedDF.queryExecution)","user":"anonymous","dateUpdated":"2018-10-11T12:59:44+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539262664431_1684967548","id":"20181011-102435_7681842","dateCreated":"2018-10-11T12:57:44+0000","dateStarted":"2018-10-11T12:59:44+0000","dateFinished":"2018-10-11T13:00:11+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5327"},{"text":"","dateUpdated":"2018-10-11T13:01:34+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539262664431_1684967548","id":"20181011-111529_296022301","dateCreated":"2018-10-11T12:57:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5328"}],"name":"Spark-Exasol-Connector","id":"2DU1T7N6Q","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}